# ============================================================================
# Construct AI Bot Configuration Example
# ============================================================================
# Copy this file to data/config.yaml and customize it for your setup.
#
# Setup Instructions:
#   1. Create data directory: mkdir -p data
#   2. Copy this file: cp config_example.yaml data/config.yaml
#   3. Edit data/config.yaml with your credentials
#   4. Set your API keys as environment variables (see below)
#   5. Run: cargo run
# ============================================================================

# ----------------------------------------------------------------------------
# System Configuration
# ----------------------------------------------------------------------------
system:
  # Base directory for projects. Used by `.list` command.
  # Optional but recommended for easier project navigation.
  projects_dir: "/home/user/Projects"

  # Admin users who can execute raw shell commands with `, <command>`
  # Must be full Matrix usernames (e.g., "@user:matrix.org")
  admin:
    - "@admin:matrix.org"

# ----------------------------------------------------------------------------
# AI Agent Configuration
# ----------------------------------------------------------------------------
# Each agent needs:
#   - protocol: The provider to use
#   - model: Specific model (optional, has defaults)
#   - API key as environment variable (see provider docs below)
#
# Available protocols: zai, gemini, claude, anthropic, openai, groq, xai, deepai
# ----------------------------------------------------------------------------

agents:
  # ==========================================================================
  # ZAI Provider (GLM Models - Recommended)
  # ==========================================================================
  # Zai provides access to General Language Models through an OpenAI-compatible API.
  #
  # IMPORTANT: Zai has separate endpoints for General vs Coding tasks.
  #
  # 1. General Endpoint (Chat, Q&A):
  #    endpoint: "https://api.z.ai/api/paas/v4/"
  #
  # 2. Coding Endpoint (Code Generation, Refactoring):
  #    endpoint: "https://api.z.ai/api/coding/paas/v4/"
  #
  # zai_coding:
  #   protocol: "openai"
  #   model: "glm-4.7"
  #   endpoint: "https://api.z.ai/api/coding/paas/v4/"
  #   requests_per_minute: 60
  #   # Requires: export ZAI_API_KEY="your-api-key" (or set api_key here)
  #   # Note: Set environment variable OPENAI_API_KEY if not setting api_key explicitly
  #
  # Available Zai Models:
  #   - glm-4.7      (Flagship)
  #   - glm-4.5      (General Purpose)
  #   - glm-4.5-flash (Fast)

  # ==========================================================================
  # Gemini Provider (Google)
  # ==========================================================================
  # Supports dynamic model discovery and automatic fallbacks.
  # API Key: Set GEMINI_API_KEY environment variable
  #
  # gemini:
  #   protocol: "gemini"
  #   model: "gemini-1.5-flash"  # Starting model
  #   requests_per_minute: 10    # Rate limiting (optional)
  #
  #   # Optional: Prioritize models using regex patterns
  #   model_order:
  #     - "flash"  # Prefer models with 'flash' in name
  #     - "pro"    # Then try models with 'pro'
  #
  #   # Optional: Explicit fallbacks if discovery fails
  #   model_fallbacks:
  #     - "gemini-1.5-flash"
  #     - "gemini-1.5-pro"
  #   # Requires: export GEMINI_API_KEY="your-api-key"

  # ==========================================================================
  # Groq Provider (Fast Inference)
  # ==========================================================================
  # Ultra-fast inference with Llama models.
  # API Key: Set GROQ_API_KEY environment variable
  #
  # groq:
  #   protocol: "groq"
  #   model: "llama-3.3-70b-versatile"
  #   requests_per_minute: 30
  #   # Requires: export GROQ_API_KEY="your-api-key"

  # ==========================================================================
  # Claude/Anthropic Provider
  # ==========================================================================
  # Anthropic's Claude models.
  # API Key: Set ANTHROPIC_API_KEY environment variable
  #
  # claude:
  #   protocol: "claude"  # or "anthropic"
  #   model: "claude-3-5-sonnet-20241022"
  #   requests_per_minute: 50  # Rate limiting (optional)
  #   # Requires: export ANTHROPIC_API_KEY="your-api-key"

  # ==========================================================================
  # OpenAI Provider
  # ==========================================================================
  # OpenAI's GPT models.
  # API Key: Set OPENAI_API_KEY environment variable
  #
  # openai:
  #   protocol: "openai"
  #   model: "gpt-4o"
  #   requests_per_minute: 50  # Rate limiting (optional)
  #   # Requires: export OPENAI_API_KEY="your-api-key"

  # ==========================================================================
  # xAI Provider (Grok)
  # ==========================================================================
  # xAI's Grok models.
  # API Key: Set XAI_API_KEY environment variable
  #
  # xai:
  #   protocol: "xai"
  #   model: "grok-beta"
  #   requests_per_minute: 50  # Rate limiting (optional)
  #   # Requires: export XAI_API_KEY="your-api-key"

  # ==========================================================================
  # DeepAI Provider (Legacy/Fallback)
  # ==========================================================================
  # Basic AI models for simple tasks.
  # API Key: Set DEEPAI_API_KEY environment variable
  #
  # deepai:
  #   protocol: "deepai"
  #   model: "standard"
  #   requests_per_minute: 10  # Rate limiting (optional)
  #   # Requires: export DEEPAI_API_KEY="your-api-key"

# ----------------------------------------------------------------------------
# Service Configuration
# ----------------------------------------------------------------------------
services:
  # Matrix (chat) service configuration
  matrix:
    username: "@your_bot:matrix.org"
    password: "your_matrix_password"
    homeserver: "https://matrix.org"
    display_name: "Construct AI Bot" # Optional: Bot's display name
    protocol: "matrix" # Optional, defaults to empty string

# ----------------------------------------------------------------------------
# Bridge Configuration
# ----------------------------------------------------------------------------
# Bridges connect Matrix rooms to AI agents and workflows.
# Each bridge has a name and can route to specific agents or use defaults.
# ----------------------------------------------------------------------------
bridges:
  # Example: Development room with Zai as default agent
  "Development":
    - service: "matrix"
      channel: "!room_id_1:matrix.org" # Replace with actual room ID
    - service: "zai" # Default agent for this room

  # Example: Staging room restricted to specific agents
  "Staging":
    - service: "matrix"
      channel: "!room_id_2:matrix.org" # Replace with actual room ID
    - agents: # Only these agents can be used in this room
        - "gemini"
        - "groq"

  # Example: Testing room with Groq
  "Testing":
    - service: "matrix"
      channel: "!room_id_3:matrix.org" # Replace with actual room ID
    - service: "groq"

# ----------------------------------------------------------------------------
# Command Permissions
# ----------------------------------------------------------------------------
# Control which shell commands can be executed through the bot.
# Modes:
#   - ask: Prompt user for confirmation (default, safe)
#   - allow: Execute without confirmation
#   - block: Never execute
# ----------------------------------------------------------------------------
commands:
  default: "ask" # Default mode for commands not listed

  # Commands that require user confirmation
  ask:
    - "sudo"
    - "rm"
    - "mv"

  # Always allowed commands (safe to execute)
  allowed:
    - "ls"
    - "cat"
    - "grep"
    - "cd"
    - "pwd"
    - "git"
    - "echo"
    - "head"
    - "tail"
    - "wc"
    - "read"
    - "find"
    - "sed"
    - "awk"

  # Blocked commands (never allowed, even for admins)
  blocked:
    - "su"
    - "passwd"
    - "chmod 777"

  # Command timeouts (in seconds)
  # Prevents commands from hanging indefinitely
  timeouts:
    short: 30 # Quick commands (ls, cat, grep, etc.)
    medium: 120 # Standard commands (git, build, test, etc.)
    long: 600 # Long-running commands (cargo build, npm install, etc.)

# ----------------------------------------------------------------------------
# MCP (Model Context Protocol) Configuration
# ----------------------------------------------------------------------------
# MCP provides secure tool execution through a sidecar server.
# The server enforces sandboxing and access controls for all agent operations.
# ----------------------------------------------------------------------------
mcp:
  # Path to the MCP server binary
  # Download from: https://github.com/modelcontextprotocol/rust-sdk
  server_path: "./mcp-filesystem-server"

  # Directories the MCP server is allowed to access
  # Agent commands (.build, .read, etc.) are restricted to these directories
  allowed_directories:
    - "./projects"
    - "./data"

  # Enable read-only mode for additional safety
  # When true, the agent cannot write files or execute commands
  # Set to false when using .build, .deploy, .modify, etc.
  readonly: false

  # Default timeout in seconds for command execution
  # Can be overridden per command based on command type
  default_timeout: 120

# ============================================================================
# Quick Start Guide
# ============================================================================
# 1. Set your API keys:
#    export ZAI_API_KEY="your-zai-key"
#    export GEMINI_API_KEY="your-gemini-key"  # if using Gemini
#
# 2. Update the configuration:
#    - Uncomment your preferred agent(s) under "agents:"
#    - Update Matrix credentials under "services:"
#    - Add your room IDs under "bridges:"
#    - Set admin users under "system:"
#
# 3. Run the bot:
#    cargo run
#
# 4. Invite the bot to your Matrix rooms
#
# 5. Start with .status to verify, then .ask for questions
# ============================================================================
